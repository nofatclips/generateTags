# generateTags
This is my approach to Dek Dekku's Tag Generator challenge (see [requirements][req]).
As a true coffee addict, I avoid writing raw JavaScript whenever possible. This document is written in [Literate CoffeeScript][lit], a recent addition to CoffeeScript that allows writing code right inside a Markdown file. It's source-code and documentation in one, with a focus on the documentation.

This very file is automatically converted to valid, readable JavaScript in by the command-line tool `coffee`, provided in the [coffee-script][cfs] Node.js package. Find the output in [`generateTags.js`][jsf]

[req]: https://github.com/nofatclips/generateTags#readme
[lit]: http://coffeescript.org/#literate
[cfs]: https://npmjs.org/package/coffee-script
[jsf]: ./generateTags.js
[ife]: http://en.wikipedia.org/wiki/IIFE

So let’s begin, shall we? (The following block comment will appear on top of the JS file)

    ###
    generateTags.js
    A JavaScript function that processes plain text or HTML (1st argument, as string)
    and produces a keyword frequency hash to facilitate tagging.
    Optional second argument: options object, governs the behaviour and output format.
    Can produce output suitable for the Wordle.net word cloud generator.
    
    This is free software (free as in free beer), published under the MIT license,
    see http://opensource.org/licenses/MIT
    
    This file is generated from its coffeescript source, see generateTags.coffee.md
    ###

## Usage and Options

Because CoffeeScript wraps everything in an [IIFE][ife] `(function(){...}).call(this);`, the `generateTags` function will be available in the `window` namespace and can usually be called without a prefix. It shall accept an options **object**, with default values as follows:

    defaults = 
      limit: 0                   # maximum number of most frequent words (0: no limit)
      blacklist: ""              # comma- or space separated strings to ignore (e.g. swear words)
                                 # in addition to stopwords
      ignoreStopwords: true      # see list of English stopwords below
      minLength: 0               # ignore shorter words (0: no minimum length)
      minFrequency: 0            # ignore words below a frequency threshold (0: no limit)
      ignoreCase: true           # by default, treat "House" and "house" as the same word
      retainProperNames: true    # don't ignore case when you see "Chuck Norris"
      ignorePunctuation: true    # only set this to false if it ¿really? matters to you
      ignoreNumbers:     true    # numbers usually aren't good candidates for key words / tags
      ignoreNonTextTags: true    # ignore <script>, <style>, <img>, <video>, <audio> and friends
      outputFormat: 'list'       # Array, sorted by frequency descending
                                 # alternative values:
                                 #   'object' ==> {'blah':23,...}
                                 #   'wordle' ==> "blah:23\n...", for http://www.wordle.net/advanced

### Example
Once the `.js` file is loaded into a document (e.g. in a `<script>` tag), you can call the function like this to analyze the current document:  
`generateTags(document.body.innerHTML, {limit:50, minLength:2, minFrequency:3, outputFormat:'wordle'})`
This'll fetch all the other options from `defaults` and output a list of the (up to) 50 most frequent words with 2 or more characters, having a frequency of at least 3, as string in the format required by Wordle.
I've tried it with these exact options on the [Codecademy Blog][ccb] with the following result (generated by [Wordle][wrdl]):

![](http://i.imgur.com/D1jyWZv.png)

By the way, [this is][scs] what Wordle generates if simply given the [URL][ccb], without any pre-processing.

[wrdl]: http://www.wordle.net/advanced
[ccb]: http://www.codecademy.com/blog/
[scs]: http://i.imgur.com/p80kvSu.png

### Some constants
We need some presets for the stopword list (stolen from [here](http://www.ranks.nl/resources/stopwords.html)) and the HTML tags to ignore (this one I made up...)

    # common English stopwords
    stopwords = "a about above after again against all am an and any are aren't as at be because been before being below between both but by can't cannot could couldn't did didn't do does doesn't doing don't down during each few for from further had hadn't has hasn't have haven't having he he'd he'll he's her here here's hers herself him himself his how how's i i'd i'll i'm i've if in into is isn't it it's its itself let's me more most mustn't my myself no nor not of off on once only or other ought our ours ourselves out over own same shan't she she'd she'll she's should shouldn't so some such than that that's the their theirs them themselves then there there's these they they'd they'll they're they've this those through to too under until up very was wasn't we we'd we'll we're we've were weren't what what's when when's where where's which while who who's whom why why's with won't would wouldn't you you'd you'll you're you've your yours yourself yourselves"
    
    html_tags = "button head script map style audio video canvas svg data"

These strings will be used in several places to compose regular expressions. I wanted to make blacklist word removal multilingual, which is why a simple `/\b(word1|word2|word3)\b/` RegExp won’t do. The problem is that `\b` (word boundary) only matches the zero-width string between **English** word and non-word characters. If we want to also remove blacklisted words from texts in other scripts, we can't rely on `\b` but have to define a set of _"non-word"_ characters instead.

    punctuation_chars = ".,:;?!¿¡\\/\\[|\\](){}«»#@$%&§£\"+*=<>^`´\\\\\\u2000-\\u2018\\u201a-\\u205f"
    non_word = "\\s#{punctuation_chars}" # whitespace or any punctuation except '’-

Here's my cheap attempt to catch more than just English capital letters (needed to identify abbreviations and multiword names):

    # capital letters: Latin, Greek, Cyrillic, Georgian (Unicode ranges)
    caps  = "[A-Z\\u00c0-\\u01b5\\u0391-\\u03a9\\u0400-\\u042f\\u10a0-\\u10c5]"

## Implementation

### Utility functions

This one will decode [HTML entities](http://www.w3.org/TR/html4/sgml/entities.html):

 - `&oslash;` becomes  ø
 - `&frac12;` becomes  ½
 - `&#28450;` becomes  漢

and so forth. __WARNING__: this only works inside a DOM environment because it needs a `document`. It'll fail in standalone JS. Source: <http://stackoverflow.com/a/2808386/1030985>

    htmlDecode = (input) ->
      return input unless document?
      (e = document.createElement 'div').innerHTML = input
      e.firstChild.nodeValue

The `remove_words()` function is used to delete stopwords and blacklisted words from the main string. It takes two parameters: the text to process and a string of space-separated or comma-separated words to remove.

    remove_words = (text, word_string) ->
      # sort them by length, descending
      words = word_string.replace(/,/g,' ').split(/\s+/).sort((a,b) -> b.length - a.length)
      
      # treat ' and ’ alike
      words = (w.replace(/'/,"['’]") for w in words) if word_string.match(/'/)
      
      # cut in batches, each 100 items max
      batches = (words.slice(100*x, 100*(x+1)) for x in [0..Math.floor(words.length/100)])
      regexes = (new RegExp("([#{non_word}])(#{batch.join('|')})(?=[#{non_word}])", "gi") for batch in batches)
      
      # hack to prevent ignoring a target at the beginning of the string (string must begin with a non-word character)
      text = " " + text
      # replace
      text = text.replace(re, "$1") for re in regexes
      text


### The actual function

    ###
    @param html: a string containing the HTML to be processed
    @param options: the options object, as follows (default values)
      limit: 0                   # maximum number of most frequent words (0: no limit)
      blacklist: ""              # comma- or space separated strings to ignore (e.g. swear words)
                                 # in addition to stopwords
      minLength: 0               # ignore shorter words (0: no minimum length)
      minFrequency: 0            # ignore words below a frequency threshold (0: no limit)
      retainProperNames: true    # don't ignore case when you see "Chuck Norris"
      ignoreCase: true           # by default, treat "House" and "house" as the same word
      ignoreStopwords: true      # see list of English stopwords below
      ignorePunctuation: true    # only set this to false if it ¿really? matters to you
      ignoreNumbers:     true    # numbers usually aren't good candidates for key words / tags
      ignoreNonTextTags: true    # ignore <script>, <style>, <img>, <video>, <audio> and friends
      outputFormat: 'list'       # Array, sorted by frequency descending
                                 # alternative values:
                                 #   'object' ==> {'blah':23,...}
                                 #   'wordle' ==> "blah:23\n...", for http://www.wordle.net/advanced
    ###
    @generateTags = (html, options) ->
      
      opts = options or {}
      for x of defaults
        opts[x] = if opts[x] is undefined then defaults[x] else opts[x]

Now, let’s get to the dirty work, step by step.

### Cleanup 1: Eliminate HTML tags

Get rid of the tags that we want to ignore completely, such as `<script>...</script>`. The RegExp is case-insensitive, so it also catches things like `<HEAD>...</head>`

      if opts.ignoreNonTextTags
        re = new RegExp "<(#{html_tags.replace(/\s/g,'|')}).+?</\\1>", "gi"
        html = html.replace re, ' '

Next, throw away __all other__ HTML tags, replacing them with spaces to avoid jamming together words from adjacent tags, e.g. `<li>foo</li><li>bar</li>`:

      html = html.replace /<.+?>/g, ' '

### Cleanup 2: replace ISO entities

      html = htmlDecode(html);

### Cleanup 3: remove blacklisted words; normalize whitespace

      console.log "removing blacklist words..." if  opts.blacklist isnt "" # debug
      html = remove_words(html, blacklist) if opts.blacklist isnt ""
      html = html.replace /\s+/g, ' '

### Identify multi-word entities (such as _United States of America_)

We need to do this **before** removing stopwords and punctuation. I have a rather naïve algorithm for identifying multiword entities: if the string `"Chuck Norris"` occurs a couple times, but `"Chuck"` **never occurs _without_** an immediately  following `"Norris"`, then `"Chuck Norris"` is considered a named entity, which we want to treat as a single keyword and  preserve capitalization on.

If we removed stopwords now, then things like `"John with Jane"` and `"John or Jane"`, would collapse into an (incorrect) `"John Jane"` entity, which we don’t want. Moreover, we *do* want to preserve repeatedly occurring things like `"World of Warcraft"` and `"The Return of the King"`, which would be reduced to `"World Warcraft"` and `"Return King"` *after* stopword removal.

If we cleaned the punctuation before looking for multiword entities, words from adjacent sentences might collapse into one, which is also undesirable. So we're going to look for strings **without** interrupting punctuation (`"Ruby on Rails"` *is* a multiword entity candidate, but `"Ruby on. Rails"` *isn’t*). For punctuation I'm going to use the same regex that is used to *remove* punctuation, see explanation below.

Now here are my completely arbitrary criteria for identifying a multiword entity:

- it starts with a capital letter
- it has up to _seven_ words (like [this one][opcw])
- it occurs *more than once* in the text
- the first word of it *never* occurs without the ones to follow (to catch `"Barack Obama"`, but ignore `"Obama said"`)

I know it's far from ideal, and I know finding named entities (person names, etc.) in texts is a science of its own (it's a Text Mining technique, and people spend years and years developing algorithms for that). This is just a very simple implementation, and probably it won't be very accurate or complete, but it'll catch some cases at least.

[opcw]: http://en.wikipedia.org/wiki/Organization_for_the_Prohibition_of_Chemical_Weapons

Now the implementation should be straightforward: we'll go from my arbitrarily chosen upper threshold of seven down to two, try and find multi-word strings that satisfy the criteria given above, remember how often they occur in the frequency hash, and then remove them from the main string, because we don't want to have *both* `"Edward John Routh"` **and** its substring `"Edward John"` in our list of names.

At this point we have to initialize the `freq` (frequencies) hash to store the frequencies of those multiword entities.

      freq  = {}
      if opts.retainProperNames

OK, let's start the loop now. From seven-word entities down to two-word entities...

        for n in [7..2]

Find: Capital letter wollowed by some non-whitespace **and non-punctuation** characters, followed by `n-1` sequences of whitespace + word. For instance, in a string like `"foo A B bar baz A B foo bar"` this regular expression will match both occurrences of `"A B"` once we're down to 2-word expressions. Note that I'm using this complicated "not-whitespace, not-punctuation" RegExp instead of the usual `\w` for "__w__ord character", because `\w` only matches the **english** alphabet and ignores things like `"that's"` and `"off-topic"`. This should work (to some extent) in multilingual texts.

          re_candidate = new RegExp "#{caps}[^#{non_word}]+( [^#{non_word}]+){#{n-1}}", 'g'
          candidates   = html.match re_candidate # array of non-overlapping matches

Next, we want to have each match only once in the array. And we're only interested in those that occur more than once in our HTML:

          uniq = [] # array to hold unique matches
          uniq.push(c) for c in candidates when c not in uniq
          uniq = (c for c in uniq when html.match(new RegExp c, 'g').length > 1)

Here comes the exciting part: we *only* want to keep the candidates whose first word doesn’t occur without the rest. We’re going to do that using the __negative look-ahead__ syntax: the regex `/Tim(?! Cook)/` will match `"Tim"` **except** when it’s followed by `" Cook"`.

          uniq = (c for c in uniq when not html.match(
            new RegExp( c.slice(0, pos = c.indexOf ' ') + "(?!#{c.slice pos})", 'g' )
          ))

Now that we’ve identified multiword candidates of length `n`, time to remove them from the string, recording their frequency in `freq`:

          for name in uniq
            re = new RegExp name, 'g'
            freq[name] = html.match(re).length
            html = html.replace re, ''

One more thing, before we kill the stopwords: I'd like to preserve abbreviations (words in CAPS). If I don't do that, the stopword removal (which is case-insensitive because it needs to kill both `"The"` and `"the"`) will incorrectly ignore abbreviations such as "[WHO](http://en.wikipedia.org/wiki/WHO)" and "[MORE](http://en.wikipedia.org/wiki/MORE_protocol)". Just as we did with multiword names, we only consider abbreviations that occur _more than once_. And because we’re using the Unicode-ish `caps` character set, this should also catch abbreviations in, say, Russian.

The code below remembers the frequency of each abbreviation, then removes it from the string.

      re_abbrv = new RegExp "#{caps}{2,}", 'g'
      abbrv_candidates = html.match re_abbrv
      uniq_abbrv = []
      uniq_abbrv.push(c) for c in abbrv_candidates when c not in uniq_abbrv
      for x in uniq_abbrv.sort((a,b) -> b.length - a.length)
        re = new RegExp x, 'g'
        if (count = html.match(re).length) > 1
          freq[x] = count
          html = html.replace(re, '')

### Cleanup 4: remove stopwords

      html = remove_words(html, stopwords) if opts.ignoreStopwords

### Cleanup 5: kill punctuation

There are dozens of ways to do this, and *none* of them is *“the correct way”*. This will in all likelihood destroy some things (email addresses, URLs? – too bad…), but it's probably still a good idea to leave the `ignorePunctuation` option on, otherwise `blah` and `blah,` will count as different words. Though I _could_ include yet anther option to preserve _certain types_ of punctuation (e.g. `!?…` at the end of words or `@` prefixed to words – for Twitter names), for now I'm just going to brutally kill __every character__ in [this Unicode range](http://en.wikipedia.org/wiki/Template:Unicode_chart_General_Punctuation) (except `’`), plus some of the common ones that aren’t in that range (`.,:;?!¿¡\/[](){}#@$%&§` or something like that), preserving just two special cases:

1. apostrophe between word characters (as in _this girl’s father’s Rock'n'Roll_)
2. hyphen between word characters (e.g. _in-depth, hands-on, one-way_)

The underscore will be spared.

A few words on usage: if `ignoreStopwords` is set to `true` (default) **or** if there’s a `blacklist`, then `ignorePunctuation` should also be true. Otherwise one ends up with floating punctuation characters that count as words (whenever a stopword or a blacklisted word adjacent to a punctuation character was removed). When we removed multiword entities and abbreviations above, we might also have left floating punctuation around. One more reason it's a good idea to get rid of it.

      if opts.ignorePunctuation
        # remove '’- if preceded by a non-word character or NOT followed by a word character
        html = html.replace(new RegExp("(([#{non_word}])['’-]|['’-](?![^#{non_word}])|^['’-])",'g'), "$2") 
        
        # remove all the other punctuation characters
        html = html.replace(new RegExp("[#{punctuation_chars}]",'g'), ' ')

### Cleanup 6: remove numbers

This will remove runs of consecutive digits. Strings like `W3C` and `Python3` will be left alone. If you want to preserve, say, dates such as `2012`, you should set `ignoreNumbers` to `false`.

      if opts.ignoreNumbers
        html = html.replace(/\s\d+\s/gi, ' ')

### Cleanup 7: kill floating punctuation, normalize word separators
Now that everything we *don't* want is finally gone, there's some whitespace and possibly some floating punctuation in between the remaining words (floating punctuation can occur when a multiword entity, an abbreviation, or a blacklist word has been removed, e.g. `"foo bad_word, bar"` becomes `"foo , bar"`). In the event that the user chose to preserve punctuation (to count `"why"` and `"why?"` separately), we still want to ignore something like `" ,. "` because counting it as a "word" would be just silly.

      html = html.replace(new RegExp("\\s[#{non_word}]+\\s",'gi'), ' ')

### Ignore case
Since all the beasts whose capitalization we want to preserve are already gone by now, we can safely convert everything eöse to lowercase, if the user so desired:

      if opts.ignoreCase
        html = html.toLowerCase()

### Hooray, an Array!
Now we can *finally* split the remaining string by whitespace to obtain an array of candidates for tags / key words:

      words = html.trim().split /\s+/

### Process the array
This step is really easy: all we need to do is traverse the array **once** and increment the frequency count for each word that we see.

      for w in words
        freq[w] or= 0
        freq[w]++

### Sort by frequency and generate the output!
Now that the `freq` hash contains all the `"word":count` pairs that we need, we can easily generate the desired output from it. There are four options that influence this process: `minLength` and `minFrequency` tell us to ignore some more items, while `limit` limits the output to a fixed number of most frequent items, and `outputFormat`, obviously, dictates the data format...

      words = (word for word of freq) # only unique words now!
      if opts.minLength > 0
        words = (word for word in words when word.length >= opts.minLength)
      
      if opts.minFrequency > 0
        words = (word for word in words when freq[word] >= opts.minFrequency)

Sort the words by frequency descending:

      words = words.sort((a,b) -> freq[b] - freq[a])

Only keep the first `limit` items:

      if opts.limit > 0
        words = words.slice 0, opts.limit

Now, the final step: generating the output in the desired format:

      if opts.outputFormat is 'list' # this is the default: nothing to do!
        return words
      else
        result = {}
        result[word] = freq[word] for word in words
        
        if opts.outputFormat is 'list'
          return result
        else # generate output for wordle
          str = ""
          str += "#{word}:#{result[word]}\n" for word of result
          return str

